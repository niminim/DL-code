# Torch
torch==2.1.1
torchvision==0.22.1
torchaudio==2.7.1
fastai==2.7.16
lightning==2.5.2.
pytorch-ignite==0.5.1

torchsummary==1.5.1
einops==0.8.1
albumentations==2.0.8
timm==1.0.15
skorch==1.0.0
kornia==0.7.4
evaluate==0.4.2
grad-cam==1.5.3
ultralytics==8.3.158
lightly==1.5.21
segmentation-models-pytorch==0.4.0
#segmentation-models-pytorch==0.3.3
huggingface-hub==0.33.0
transformers==4.52.4
diffusers==0.33.1

# Model Compression
torchao==0.11.0
quanto==0.2.0
accelerate==1.8.1
deepspeed==0.17.1
torch-pruning==1.5.3

# Vision general
optuna==3.6.1
opencv-python==4.9.0.80
small-vision==0.1.3
scikit-image==0.24.0
python-ffmpeg==2.0.12

# NLP
open-clip-torch==2.31.0
scikit-llm==1.4.1
nltk==3.9.1
# gensim==4.3.3 # word vector
# gensim 4.3.3 depends on numpy<2.0 and >=1.18.5
vllm==0.9.1 # 0.6.6.post1 works ok with coqui-tts==0.24.0
peft==0.14.0
langchain==0.3.18


# TTS_code
TTS==0.22.0
coqui-tts==0.24.0 # dont use 0.25.0! It ruins it and switches between different voices (also male and female). 0.25.1 is ok (speech is slightly faster)
gTTS==2.5.4
soundfile==0.12.1
librosa==0.10.2.post1
sounddevice==0.5.1
espeakng==1.0.3
py-espeak-ng==0.1.8
speechbrain==1.0.1
ffmpeg-python==0.2.0 # (also for vision)
pystoi==0.4.1
pydub==0.25.1
simpleaudio==1.0.4


# ML
scikit-learn==1.5.2
xgboost==2.1.1
catboost==1.2.2
lightgbm==4.5.0
# Fireducks==1.2.2 ((pandas gpu alt, alsu cudf. haven't tried that)

scipy==1.14.1
numpy==2.1.2


shap==0.44.1

# Plot
seaborn==0.13.2
plotly==5.22.0
bokeh==3.5.0
altair==5.4.1

# monitoring
neptune==1.10.4

