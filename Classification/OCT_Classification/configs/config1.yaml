model:
  architecture: efficientnet_b1  # Model architecture - efficientnet_b0, efficientnet_b1, mobilenetv3, mixnet
  in_channels: 3 # input channels in the data
  num_classes: 4 # number of classes in the classification task
  pretrained: true  # Use pretrained weights


train:
  input_size: [224,224] # (h,w)
  lr: 0.001  # Initial learning rate
  lr_decay:
    rate: 0.2 # Decay rate
    step_size: 7  # Decay step size
  batch_size: 32  # Batch size for training
  epochs: 10  # Number of training epochs
  optim: SGD  # Optimizer type
  optim_params:
    momentum: 0.9
    nesterov: true
  bs_train: 48 # train batch-size
  bs_test: 48 # test batch-size
  loss_fn: CrossEntropyLoss  # Loss function
  regularization:
    l2: 0.01  # L2 regularization factor


data:
  train_path: /home/nim/Downloads/OCT_and_X-ray/OCT2017/train_split_0_035/train  # Path to training data
  val_path: /home/nim/Downloads/OCT_and_X-ray/OCT2017/train_split_0_035/val  # Path to validation data
  test_path: /home/nim/Downloads/OCT_and_X-ray/OCT2017/test  # Path to test data
  preprocess:
    resize: [224, 224]  # Resize dimensions for input images
    normalize:  # Normalization parameters
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
  augmentation:  # Data augmentation settings
    random_flip: true
    random_crop: true
    rotation_degree: 10

environment:
  use_gpu: true  # Flag to use GPU if available
  gpu_id: 0  # GPU ID for multi-GPU setups
  seed: 42  # Seed for reproducibility
  num_workers: 4  # Number of workers for data loading

logging:
  logfile_path: /home/nim/venv/DL-code/Classification/OCT_Classification/logs/training_logs
  log_interval: 10  # Interval for printing logs
  save_model: true  # Flag to save the model after training
  checkpoint_dir: /path/to/save/checkpoints  # Directory to save checkpoints
  tensorboard:
    use_tensorboard: true  # Enable TensorBoard logging
    log_dir: /path/to/save/tensorboard_logs  # Directory for TensorBoard logs
